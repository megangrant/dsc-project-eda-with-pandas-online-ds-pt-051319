{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - EDA with Pandas Using the Boston Housing Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this section you've learned a lot about importing, cleaning up, analyzing (using descriptive statistics) and visualizing data. In this a more free form project you'll get a chance to practice all of these skills with the Boston Housing data set, which contains housing values in suburbs of Boston. The Boston Housing Data is commonly used by aspiring data scientists.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Load csv files using Pandas\n",
    "* Find variables with high correlation\n",
    "* Create box plots\n",
    "\n",
    "## Goals\n",
    "\n",
    "Use your data munging and visualization skills to conduct an exploratory analysis of the dataset below. At a minimum, this should include:\n",
    "\n",
    "* Loading the data (which is stored in the file `train.csv`)\n",
    "* Use built-in python functions to explore measures of centrality and dispersion for at least 3 variables\n",
    "* Create *meaningful* subsets of the data using selection operations using `.loc`, `.iloc` or related operations. Explain why you used the chosen subsets and do this for 3 possible 2-way splits. State how you think the 2 measures of centrality and/or dispersion might be different for each subset of the data. Examples of potential splits:\n",
    "    - Create a 2 new dataframes based on your existing data, where one contains all the properties next to the Charles river, and the other one contains properties that aren't.\n",
    "    - Create 2 new dataframes based on a certain split for crime rate.\n",
    "* Next, use histograms and scatterplots to see whether you observe differences for the subsets of the data. Make sure to use subplots so it is easy to compare the relationships.\n",
    "\n",
    "## Variable Descriptions\n",
    "\n",
    "This data frame contains the following columns:\n",
    "\n",
    "#### crim  \n",
    "per capita crime rate by town.\n",
    "\n",
    "#### zn  \n",
    "proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "#### indus  \n",
    "proportion of non-retail business acres per town.\n",
    "\n",
    "#### chas  \n",
    "Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "\n",
    "#### nox  \n",
    "nitrogen oxides concentration (parts per 10 million).\n",
    "\n",
    "#### rm  \n",
    "average number of rooms per dwelling.\n",
    "\n",
    "#### age  \n",
    "proportion of owner-occupied units built prior to 1940.\n",
    "\n",
    "#### dis  \n",
    "weighted mean of distances to five Boston employment centers.\n",
    "\n",
    "#### rad  \n",
    "index of accessibility to radial highways.\n",
    "\n",
    "#### tax  \n",
    "full-value property-tax rate per $10,000.\n",
    "\n",
    "#### ptratio  \n",
    "pupil-teacher ratio by town.\n",
    "\n",
    "#### black  \n",
    "1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.\n",
    "\n",
    "#### lstat  \n",
    "lower status of the population (percent).\n",
    "\n",
    "#### medv  \n",
    "median value of owner-occupied homes in $10000s.\n",
    "  \n",
    "  \n",
    "  \n",
    "Source\n",
    "Harrison, D. and Rubinfeld, D.L. (1978) Hedonic prices and the demand for clean air. J. Environ. Economics and Management 5, 81â€“102.\n",
    "\n",
    "Belsley D.A., Kuh, E. and Welsch, R.E. (1980) Regression Diagnostics. Identifying Influential Data and Sources of Collinearity. New York: Wiley.\n",
    "\n",
    "## Summary\n",
    "\n",
    "Congratulations, you've completed your first \"freeform\" exploratory data analysis of a popular data set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Megan's section for exploratory data analysis\n",
    "\n",
    "In this section I will conduct the data exploration required above. All inputs from this point on will be code (no markdowns) with hashtags to denote explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333 entries, 0 to 332\n",
      "Data columns (total 15 columns):\n",
      "ID         333 non-null int64\n",
      "crim       333 non-null float64\n",
      "zn         333 non-null float64\n",
      "indus      333 non-null float64\n",
      "chas       333 non-null int64\n",
      "nox        333 non-null float64\n",
      "rm         333 non-null float64\n",
      "age        333 non-null float64\n",
      "dis        333 non-null float64\n",
      "rad        333 non-null int64\n",
      "tax        333 non-null int64\n",
      "ptratio    333 non-null float64\n",
      "black      333 non-null float64\n",
      "lstat      333 non-null float64\n",
      "medv       333 non-null float64\n",
      "dtypes: float64(11), int64(4)\n",
      "memory usage: 39.1 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "3   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "4   7  0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311   \n",
       "\n",
       "   ptratio   black  lstat  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     18.7  394.63   2.94  33.4  \n",
       "3     18.7  396.90   5.33  36.2  \n",
       "4     15.2  395.60  12.43  22.9  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mean of the town crime rate is 3.360341471471471 with a standard deviation of 7.3522718367811075. This data shows that either there are possibly outliers in the data, or that the crime rate varies a lot town to town, as the SD is over twice the size of the mean value.\n",
      "    Mean of the number of rooms per dwelling is 6.265618618618616 with a standard deviation of 0.7039515757334481. There are therefore few outliers in this data, and most towns have a similar number of rooms per dwelling.\n",
      "    Mean distance from an employment centre is 3.7099336336336335with a standard deviation of 1.9811230514407006. This shows that it's unlikely that there's outliers.\n"
     ]
    }
   ],
   "source": [
    "# Use built-in python functions to explore measures of centrality and dispersion for at least 3 variables\n",
    "crim_rate_mean = df['crim'].mean()\n",
    "crim_rate_sd = df['crim'].std()\n",
    "num_rooms_mean = df['rm'].mean()\n",
    "num_rooms_sd = df['rm'].std()\n",
    "employment_centre_mean = df['dis'].mean()\n",
    "employment_centre_sd = df['dis'].std()\n",
    "print(\"    Mean of the town crime rate is \" + str(crim_rate_mean) + \" with a standard deviation of \" + str(crim_rate_sd) + \". This data shows that either there are possibly outliers in the data, or that the crime rate varies a lot town to town, as the SD is over twice the size of the mean value.\")\n",
    "print(\"    Mean of the number of rooms per dwelling is \" + str(num_rooms_mean) + \" with a standard deviation of \" + str(num_rooms_sd) + \". There are therefore few outliers in this data, and most towns have a similar number of rooms per dwelling.\")\n",
    "print(\"    Mean distance from an employment centre is \" + str(employment_centre_mean) + \"with a standard deviation of \" + str(employment_centre_sd) + \". This shows that it's unlikely that there's outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create meaningful subsets of the data using selection operations using .loc, .iloc or related operations. Explain why you used the chosen subsets and do this for 3 possible 2-way splits. State how you think the 2 measures of centrality and/or dispersion might be different for each subset of the data. Examples of potential splits:\n",
    "#Create a 2 new dataframes based on your existing data, where one contains all the properties next to the Charles river, and the other one contains properties that aren't.\n",
    "#Create 2 new dataframes based on a certain split for crime rate.\n",
    "\n",
    "#Not sure what data they want me to manipulate, going to ask my tutor before proceeding with the data splits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
